# This code is part of Qiskit.
#
# (C) Copyright IBM 2023.
#
# This code is licensed under the Apache License, Version 2.0. You may
# obtain a copy of this license in the LICENSE.txt file in the root directory
# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.
#
# Any modifications or derivative works of this code must retain this
# copyright notice, and modified files need to carry a notice indicating
# that they have been altered from the originals.

"""A Sampling Neural Network implementation based on the Sampler primitive."""

from __future__ import annotations

from typing import Sequence, Callable

import numpy as np
from qiskit import QuantumCircuit
from qiskit.circuit import Parameter
from qiskit.primitives import BaseSampler, SamplerResult
from qiskit.utils import algorithm_globals

from qiskit_machine_learning.neural_networks import SamplerQNN


class SamplingQNN(SamplerQNN):
    """
    A sampling neural network that generate samples instead of probabilities. This network extends
    :class:`~qiskit_machine_learning.neural_networks.SamplerQNN`, generates samples out of the
    quasi-probabilities returned by the sampler primitive, and returns them. This network to be
    replaced/updated when a new primitive that can return samples will be introduced.

    This network provides only the ``forward`` method. The method constructs a multinomial
    distribution for each quasi-distribution from the sampler results, samples ``num_shots`` values
    from this distribution, and applies ``interpret`` to the sampled values. The interpreted values
    are returned in an array of shape ``(num_samples, num_shots, *interpret_shape)``. Where
    ``num_samples`` is the number of samples (or batch size in other words) in the dataset and
    ``interpret_shape`` is the shape of the output of the ``interpret`` function. If the function
    returns a single number then the interpret shape is ``1``, if the function returns an array,
    then the interpret shape is the shape of this array.

    The ``backward`` always returns a tuple ``(None, None)``.

    In this example the network generates samples without custom interpretation. The circuit has two
    qubits, thus there are four possible outcomes, but in this setup the network generates evenly
    distributed outcomes of ``0`` and ``1``. The network does not take any input data.

    .. code-block::

        import numpy as np
        from qiskit import QuantumCircuit
        from qiskit.circuit import Parameter

        from qiskit_machine_learning.neural_networks.sampling_qnn import SamplingQNN

        qc = QuantumCircuit(2)

        qc.ry(Parameter("0"), 0)
        qc.ry(Parameter("1"), 1)
        qc.rx(np.pi / 2, 0)

        qnn = SamplingQNN(circuit=qc, num_shots=10, input_params=[], weight_params=qc.parameters)
        qnn.forward(input_data=None, weights=[0, 0])
    """

    def __init__(
        self,
        *,
        circuit: QuantumCircuit,
        num_shots: int,
        sampler: BaseSampler | None = None,
        input_params: Sequence[Parameter] | None = None,
        weight_params: Sequence[Parameter] | None = None,
        interpret: Callable[[int], int | tuple[int, ...]] | None = None,
    ):
        """
        Args:
            circuit: The parametrized quantum circuit that generates the samples of this network.
            sampler: The sampler primitive used to compute the neural network's results.
                If ``None`` is given, a default instance of the reference sampler defined
                by :class:`~qiskit.primitives.Sampler` will be used.
            num_shots: A positive number of shots for each circuit to sample from the
                quasi-distribution generated by the sampler. The default is 1024.
            input_params: The parameters of the circuit corresponding to the input.
            weight_params: The parameters of the circuit corresponding to the trainable weights.
            interpret: A callable that maps the measured integer to another unsigned integer or
                tuple of unsigned integers. These are used as new indices for the (potentially
                sparse) output array. If no interpret function is
                passed, then an identity function will be used by this neural network.

        Raises:
            ValueError:
                if non-positive number of shot is passed.
        """
        if num_shots is None:
            num_shots = 1024
        if num_shots < 1:
            raise ValueError(f"A positive number of shot is required, got {num_shots} instead.")
        self._num_shots = num_shots

        def identity(x):
            return x

        if interpret is None:
            interpret = identity

        # derive sampling shape and pass it as output shape to the superclass
        output_shape = self._compute_sampling_shape(interpret)

        super().__init__(
            circuit=circuit,
            sampler=sampler,
            input_params=input_params,
            weight_params=weight_params,
            interpret=interpret,
            output_shape=output_shape,
            input_gradients=False,
        )

    def _compute_sampling_shape(
        self, interpret: Callable[[int], int | tuple[int, ...]] | None = None
    ) -> tuple[int, ...]:
        # this definition is required by mypy
        output_shape: tuple[int, ...] = (-1,)

        if interpret is not None:
            result = np.array(interpret(0))  # infer shape from the function
            if len(result.shape) == 0:
                # interpret returned a single number
                output_shape = (self._num_shots, 1)
            else:
                # interpret returned an array
                output_shape = (self._num_shots, *result.shape)
        else:
            # no mapping of the network's output, it is a plain number
            output_shape = (self._num_shots, 1)

        return output_shape

    def _postprocess(self, num_samples: int, result: SamplerResult) -> np.ndarray:
        """
        Post-processing during forward pass of the network. This is an essential step, it differs
        from post-processing done by other networks. The method constructs a multinomial
        distribution for each quasi-distribution from the sampler results.

        Args:
             num_samples: the number of samples in the dataset.
             result: the result of executing a neural network circuit on the dataset.

        Returns:
            an array of shape ``(num_samples, num_shots, *interpret_shape)``.
        """
        all_samples = np.zeros((num_samples, *self._output_shape))

        for i in range(num_samples):
            # we need probabilities of all possible outcomes, since the result contains a dictionary
            # some keys (possible outcomes) can be missing.
            num_qubits = self._circuit.num_qubits
            distribution = result.quasi_dists[i].nearest_probability_distribution()
            probabilities = [distribution.get(i, 0) for i in range(2**num_qubits)]

            # samples for the i-th circuit (or sample) from the batch
            circuit_samples = algorithm_globals.random.multinomial(self._num_shots, probabilities)
            circuit_outcomes = []
            for sample, reps in enumerate(circuit_samples):
                circuit_outcomes += [sample] * reps

            algorithm_globals.random.shuffle(circuit_outcomes)

            for j, circuit_outcome in enumerate(circuit_outcomes):
                all_samples[i, j, :] = self._interpret(circuit_outcome)

        return all_samples

    def _backward(
        self, input_data: np.ndarray | None, weights: np.ndarray | None
    ) -> tuple[None, None]:
        return None, None
