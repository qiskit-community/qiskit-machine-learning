<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" />

    <!-- Generated with Sphinx 7.4.7 and Furo 2024.01.29 -->
        <title>qiskit_machine_learning.optimizers.spsa - Qiskit Machine Learning 0.8.2</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=82a976d7" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/qiskit-sphinx-theme.css?v=fe84956c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/qiskit-ecosystem.css?v=745c5aa7" />
    <link rel="stylesheet" type="text/css" href="../../../_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600&family=IBM+Plex+Sans:ital,wght@0,400;0,600;1,400;1,600&display=swap" rel="stylesheet">
<script src="../../../_static/js/web-components/top-nav-bar.js"></script>
<script>
  (function () {
    window._analytics = {
      segment_key: 'ffdYLviQze3kzomaINXNk6NwpY9LlXcw',
      coremetrics: false,
      optimizely: false,
      googleAddServices: false,
      fullStory: false,
      autoPageEventSpa: false,
      autoFormEvents: false,
      autoPageView: false
    }

    window.digitalData = {
      page: {
        pageInfo: {
          productTitle: 'IBM Q Experience',
          analytics: {
            category: 'Qiskit.org'
          }
        }
      }
    }
  }());
</script>
<script src="https://cloud.ibm.com/analytics/build/bluemix-analytics.min.js"></script>
<script>
  (function () {
    'use strict'

    if (!window.bluemixAnalytics || !window.digitalData) { return }

    const category = window.digitalData.page.pageInfo.analytics.category
    const productTitle = window.digitalData.page.pageInfo.productTitle
    const routeName = 'documentation'

    window.bluemixAnalytics.pageEvent(category, routeName, {
      navigationType: 'pushState',
      productTitle: productTitle,
      title: document.title
    })

    window.trackCta = (action) => {
      if (!window.bluemixAnalytics || !window.digitalData) { return }

      const category = window.digitalData.page.pageInfo.analytics.category
      const productTitle = window.digitalData.page.pageInfo.productTitle

      window.bluemixAnalytics.trackEvent('CTA Clicked', {
        productTitle,
        category,
        CTA: action
      })
    }

  }());
</script></head>
  <body>
    
    <script>document.body.dataset.theme = "light";</script>
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg id="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32">
      <defs><style>.cls-1{fill:none;}</style></defs>
      <path d="M28,4H4A2,2,0,0,0,2,6V26a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V6A2,2,0,0,0,28,4ZM4,6H20V26H4ZM28,26H22V6h6Z"/>
      <rect id="_Transparent_Rectangle_" data-name="&lt;Transparent Rectangle&gt;" class="cls-1" width="32" height="32"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg id="icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32">
      <defs><style>.cls-1{fill:none;}</style></defs>
      <rect x="4" y="6" width="24" height="2"/>
      <rect x="4" y="24" width="24" height="2"/>
      <rect x="4" y="12" width="24" height="2"/>
      <rect x="4" y="18" width="24" height="2"/>
      <rect id="_Transparent_Rectangle_" data-name="&lt;Transparent Rectangle&gt;" class="cls-1" width="32" height="32"/>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg version="1.1" id="icon" xmlns="http://www.w3.org/2000/svg" x="0px" y="0px"
         viewBox="0 0 32 32" style="enable-background:new 0 0 32 32;" xml:space="preserve"><polygon points="22,16 12,26 10.6,24.6 19.2,16 10.6,7.4 12,6 " stroke="currentColor"/>
      <rect id="_x3C_Transparent_Rectangle_x3E_" fill="none" width="32" height="32"/>
    </svg>
  </symbol>
  <symbol id="svg-new-tab" viewBox="0 0 32 32">
    <svg id="icon" xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 32 32">
      <defs>
        <style>
          .cls-1 {
            fill: none;
          }
        </style>
      </defs>
      <path fill="#6929C4" d="M26,28H6a2.0027,2.0027,0,0,1-2-2V6A2.0027,2.0027,0,0,1,6,4H16V6H6V26H26V16h2V26A2.0027,2.0027,0,0,1,26,28Z"/>
      <polygon fill="#6929C4" points="20 2 20 4 26.586 4 18 12.586 19.414 14 28 5.414 28 12 30 12 30 2 20 2"/>
      <rect id="_Transparent_Rectangle_" data-name="&lt;Transparent Rectangle&gt;" class="cls-1" width="32" height="32"/>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../index.html"><div class="brand">Qiskit Machine Learning 0.8.2</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><div class="sidebar-brand">
  <a href="https://www.qiskit.org/ecosystem">
    <div class="sidebar-logo-container">
      <img class="sidebar-logo" src="../../../_static/images/ecosystem-logo.svg" alt="Qiskit Ecosystem logo"/>
    </div>
  </a>
  
  <span class="sidebar-brand-text">Qiskit Machine Learning 0.8.2</span>
</div><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../migration/index.html">Migration Guide</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Migration Guide</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../migration/01_migration_guide_0.5.html">Qiskit Machine Learning v0.5 Migration Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../migration/02_migration_guide_0.8.html">Qiskit Machine Learning v0.8 Migration Guide</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../tutorials/index.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/01_neural_networks.html">Quantum Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/02_neural_network_classifier_and_regressor.html">Neural Network Classifier &amp; Regressor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/02a_training_a_quantum_model_on_a_real_dataset.html">Training a Quantum Model on a Real Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/03_quantum_kernel.html">Quantum Kernel Machine Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/04_torch_qgan.html">PyTorch qGAN Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/05_torch_connector.html">Torch Connector and Hybrid QNNs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/07_pegasos_qsvc.html">Pegasos Quantum Support Vector Classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/08_quantum_kernel_trainer.html">Quantum Kernel Training for Machine Learning Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/09_saving_and_loading_models.html">Saving, Loading Qiskit Machine Learning Models and Continuous Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/10_effective_dimension.html">Effective Dimension of Qiskit Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/11_quantum_convolutional_neural_networks.html">The Quantum Convolution Neural Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/12_quantum_autoencoder.html">The Quantum Autoencoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/13_quantum_bayesian_inference.html">Quantum Bayesian Inference</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../apidocs/qiskit_machine_learning.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of API Reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.QiskitMachineLearningError.html">QiskitMachineLearningError</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apidocs/qiskit_machine_learning.algorithms.html">Quantum machine learning algorithms (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_machine_learning.algorithms</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Quantum machine learning algorithms (qiskit_machine_learning.algorithms)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.algorithms.TrainableModel.html">TrainableModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.algorithms.ObjectiveFunction.html">ObjectiveFunction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.algorithms.SerializableModelMixin.html">SerializableModelMixin</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.algorithms.BinaryObjectiveFunction.html">BinaryObjectiveFunction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.algorithms.MultiClassObjectiveFunction.html">MultiClassObjectiveFunction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.algorithms.OneHotObjectiveFunction.html">OneHotObjectiveFunction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.algorithms.PegasosQSVC.html">PegasosQSVC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.algorithms.QSVC.html">QSVC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.algorithms.VQC.html">VQC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.algorithms.NeuralNetworkClassifier.html">NeuralNetworkClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.algorithms.QSVR.html">QSVR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.algorithms.VQR.html">VQR</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.algorithms.NeuralNetworkRegressor.html">NeuralNetworkRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.algorithms.QBayesian.html">QBayesian</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apidocs/qiskit_machine_learning.circuit.library.html">Circuit library for machine learning applications (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_machine_learning.circuit.library</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of Circuit library for machine learning applications (qiskit_machine_learning.circuit.library)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.circuit.library.RawFeatureVector.html">RawFeatureVector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.circuit.library.QNNCircuit.html">QNNCircuit</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apidocs/qiskit_machine_learning.connectors.html">Connectors (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_machine_learning.connectors</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of Connectors (qiskit_machine_learning.connectors)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.connectors.TorchConnector.html">TorchConnector</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apidocs/qiskit_machine_learning.datasets.html">Datasets (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_machine_learning.datasets</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of Datasets (qiskit_machine_learning.datasets)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.datasets.ad_hoc_data.html">ad_hoc_data</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apidocs/qiskit_machine_learning.gradients.html">Gradients (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_machine_learning.gradients</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of Gradients (qiskit_machine_learning.gradients)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.gradients.BaseEstimatorGradient.html">BaseEstimatorGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.gradients.BaseSamplerGradient.html">BaseSamplerGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.gradients.EstimatorGradientResult.html">EstimatorGradientResult</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.gradients.SamplerGradientResult.html">SamplerGradientResult</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.gradients.LinCombEstimatorGradient.html">LinCombEstimatorGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.gradients.LinCombSamplerGradient.html">LinCombSamplerGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.gradients.ParamShiftEstimatorGradient.html">ParamShiftEstimatorGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.gradients.ParamShiftSamplerGradient.html">ParamShiftSamplerGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.gradients.SPSAEstimatorGradient.html">SPSAEstimatorGradient</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.gradients.SPSASamplerGradient.html">SPSASamplerGradient</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apidocs/qiskit_machine_learning.kernels.html">Quantum kernels (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_machine_learning.kernels</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of Quantum kernels (qiskit_machine_learning.kernels)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.kernels.BaseKernel.html">BaseKernel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.kernels.FidelityQuantumKernel.html">FidelityQuantumKernel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.kernels.FidelityStatevectorKernel.html">FidelityStatevectorKernel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.kernels.TrainableKernel.html">TrainableKernel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.kernels.TrainableFidelityQuantumKernel.html">TrainableFidelityQuantumKernel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.kernels.TrainableFidelityStatevectorKernel.html">TrainableFidelityStatevectorKernel</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../apidocs/qiskit_machine_learning.kernels.algorithms.html">Quantum Kernel Algorithms</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of Quantum Kernel Algorithms</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.kernels.algorithms.QuantumKernelTrainer.html">QuantumKernelTrainer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.kernels.algorithms.QuantumKernelTrainerResult.html">QuantumKernelTrainerResult</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apidocs/qiskit_machine_learning.neural_networks.html">Quantum neural networks (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_machine_learning.neural_networks</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of Quantum neural networks (qiskit_machine_learning.neural_networks)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.neural_networks.NeuralNetwork.html">NeuralNetwork</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.neural_networks.EstimatorQNN.html">EstimatorQNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.neural_networks.SamplerQNN.html">SamplerQNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.neural_networks.EffectiveDimension.html">EffectiveDimension</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.neural_networks.LocalEffectiveDimension.html">LocalEffectiveDimension</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apidocs/qiskit_machine_learning.optimizers.html">Optimizers (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_machine_learning.optimizers</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of Optimizers (qiskit_machine_learning.optimizers)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.OptimizerResult.html">OptimizerResult</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.Optimizer.html">Optimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.Minimizer.html">Minimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.optimizer_utils.html">optimizer_utils</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.SteppableOptimizer.html">SteppableOptimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.AskData.html">AskData</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.TellData.html">TellData</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.OptimizerState.html">OptimizerState</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.ADAM.html">ADAM</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.AQGD.html">AQGD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.CG.html">CG</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.COBYLA.html">COBYLA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.L_BFGS_B.html">L_BFGS_B</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.GSLS.html">GSLS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.GradientDescent.html">GradientDescent</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.GradientDescentState.html">GradientDescentState</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.NELDER_MEAD.html">NELDER_MEAD</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.NFT.html">NFT</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.P_BFGS.html">P_BFGS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.POWELL.html">POWELL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.SLSQP.html">SLSQP</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.SPSA.html">SPSA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.QNSPSA.html">QNSPSA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.TNC.html">TNC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.SciPyOptimizer.html">SciPyOptimizer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.UMDA.html">UMDA</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.CRS.html">CRS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.DIRECT_L.html">DIRECT_L</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.DIRECT_L_RAND.html">DIRECT_L_RAND</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.ESCH.html">ESCH</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.optimizers.ISRES.html">ISRES</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apidocs/qiskit_machine_learning.state_fidelities.html">State Fidelities (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_machine_learning.state_fidelities</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of State Fidelities (qiskit_machine_learning.state_fidelities)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.state_fidelities.BaseStateFidelity.html">BaseStateFidelity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.state_fidelities.ComputeUncompute.html">ComputeUncompute</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.state_fidelities.StateFidelityResult.html">StateFidelityResult</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../apidocs/qiskit_machine_learning.utils.html">Utility functions and classes (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_machine_learning.utils</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of Utility functions and classes (qiskit_machine_learning.utils)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../apidocs/qiskit_machine_learning.utils.loss_functions.html">Loss Functions (<code class="xref py py-mod docutils literal notranslate"><span class="pre">qiskit_machine_learning.utils.loss_functions</span></code>)</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of Loss Functions (qiskit_machine_learning.utils.loss_functions)</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.utils.loss_functions.Loss.html">Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.utils.loss_functions.KernelLoss.html">KernelLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.utils.loss_functions.L1Loss.html">L1Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.utils.loss_functions.L2Loss.html">L2Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.utils.loss_functions.CrossEntropyLoss.html">CrossEntropyLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../stubs/qiskit_machine_learning.utils.loss_functions.SVCLoss.html">SVCLoss</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/qiskit-community/qiskit-machine-learning">GitHub</a></li>
</ul>

</div></div><div class="qiskit-translations-container" aria-label="languages">
  <input id="translations-checkbox" name="translations-checkbox" role="switch" type="checkbox">
  <div class="qiskit-translations-header-container"><label for="translations-checkbox">
      <p role="note">English</p>
      <div class="qiskit-translations-toggle-container">
        <div class="visually-hidden">Toggle translations list</div>
        <i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i>
      </div>
    </label>
  </div>
  <div class="qiskit-translations-list-container">
    <ul>
      
        <li><a href="/qiskit-machine-learning/_modules/qiskit_machine_learning/optimizers/spsa.html">English</a></li>
      
        <li><a href="/qiskit-machine-learning/locale/ja_JP/_modules/qiskit_machine_learning/optimizers/spsa.html">Japanese</a></li>
      
        <li><a href="/qiskit-machine-learning/locale/es_UN/_modules/qiskit_machine_learning/optimizers/spsa.html">Spanish</a></li>
      
    </ul>
  </div>
  <script>
    document.querySelectorAll('.version').forEach((element) => {
      element.addEventListener('click', (evt) => {
        const hash = window.location.hash;
        const complete_url = evt.target.href + hash;
        window.location = complete_url;
        evt.preventDefault();
      });
    });
  </script>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <h1>Source code for qiskit_machine_learning.optimizers.spsa</h1><div class="highlight"><pre>
<span></span><span class="c1"># This code is part of a Qiskit project.</span>
<span class="c1">#</span>
<span class="c1"># (C) Copyright IBM 2018, 2024.</span>
<span class="c1">#</span>
<span class="c1"># This code is licensed under the Apache License, Version 2.0. You may</span>
<span class="c1"># obtain a copy of this license in the LICENSE.txt file in the root directory</span>
<span class="c1"># of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.</span>
<span class="c1">#</span>
<span class="c1"># Any modifications or derivative works of this code must retain this</span>
<span class="c1"># copyright notice, and modified files need to carry a notice indicating</span>
<span class="c1"># that they have been altered from the originals.</span>

<span class="sd">&quot;&quot;&quot;Simultaneous Perturbation Stochastic Approximation (SPSA) optimizer.</span>

<span class="sd">This implementation allows both standard first-order and second-order SPSA.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Iterator</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">SupportsFloat</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>

<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">algorithm_globals</span>

<span class="kn">from</span> <span class="nn">.optimizer</span> <span class="kn">import</span> <span class="n">Optimizer</span><span class="p">,</span> <span class="n">OptimizerSupportLevel</span><span class="p">,</span> <span class="n">OptimizerResult</span><span class="p">,</span> <span class="n">POINT</span>

<span class="c1"># number of function evaluations, parameters, loss, stepsize, accepted</span>
<span class="n">CALLBACK</span> <span class="o">=</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">SupportsFloat</span><span class="p">,</span> <span class="nb">bool</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span>
<span class="n">TERMINATIONCHECKER</span> <span class="o">=</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">SupportsFloat</span><span class="p">,</span> <span class="nb">bool</span><span class="p">],</span> <span class="nb">bool</span><span class="p">]</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="SPSA">
<a class="viewcode-back" href="../../../stubs/qiskit_machine_learning.optimizers.SPSA.html#qiskit_machine_learning.optimizers.SPSA">[docs]</a>
<span class="k">class</span> <span class="nc">SPSA</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Simultaneous Perturbation Stochastic Approximation (SPSA) optimizer.</span>

<span class="sd">    SPSA [1] is a gradient descent method for optimizing systems with multiple unknown parameters.</span>
<span class="sd">    As an optimization method, it is appropriately suited to large-scale population models,</span>
<span class="sd">    adaptive modeling, and simulation optimization.</span>

<span class="sd">    .. seealso::</span>

<span class="sd">        Many examples are presented at the `SPSA website &lt;http://www.jhuapl.edu/SPSA&gt;`__.</span>

<span class="sd">    The main feature of SPSA is the stochastic gradient approximation, which requires only two</span>
<span class="sd">    measurements of the objective function, regardless of the dimension of the optimization</span>
<span class="sd">    problem.</span>

<span class="sd">    Additionally, to standard first-order SPSA, where only gradient information is used, this</span>
<span class="sd">    implementation also allows second-order SPSA (2-SPSA) [2]. In 2-SPSA we also estimate the</span>
<span class="sd">    Hessian of the loss with a stochastic approximation and multiply the gradient with the</span>
<span class="sd">    inverse Hessian to take local curvature into account and improve convergence.</span>
<span class="sd">    Notably this Hessian estimate requires only a constant number of function evaluations</span>
<span class="sd">    unlike an exact evaluation of the Hessian, which scales quadratically in the number of</span>
<span class="sd">    function evaluations.</span>

<span class="sd">    .. note::</span>

<span class="sd">        SPSA can be used in the presence of noise, and it is therefore indicated in situations</span>
<span class="sd">        involving measurement uncertainty on a quantum computation when finding a minimum.</span>
<span class="sd">        If you are executing a variational algorithm using a Quantum ASseMbly Language (QASM)</span>
<span class="sd">        simulator or a real device, SPSA would be the most recommended choice among the optimizers</span>
<span class="sd">        provided here.</span>

<span class="sd">    The optimization process can include a calibration phase if neither the ``learning_rate`` nor</span>
<span class="sd">    ``perturbation`` is provided, which requires additional functional evaluations.</span>
<span class="sd">    (Note that either both or none must be set.) For further details on the automatic calibration,</span>
<span class="sd">    please refer to the supplementary information section IV. of [3].</span>

<span class="sd">    .. note::</span>

<span class="sd">        This component has some function that is normally random. If you want to reproduce behavior</span>
<span class="sd">        then you should set the random number generator seed in the ``algorithm_globals``</span>
<span class="sd">        (``qiskit_machine_learning.utils.algorithm_globals.random_seed = seed``).</span>


<span class="sd">    Examples:</span>

<span class="sd">        This short example runs SPSA for the ground state calculation of the ``Z ^ Z``</span>
<span class="sd">        observable where the ansatz is a ``PauliTwoDesign`` circuit.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            import numpy as np</span>
<span class="sd">            from qiskit_machine_learning.optimizers import SPSA</span>
<span class="sd">            from qiskit.circuit.library import PauliTwoDesign</span>
<span class="sd">            from qiskit.primitives import Estimator</span>
<span class="sd">            from qiskit.quantum_info import SparsePauliOp</span>

<span class="sd">            ansatz = PauliTwoDesign(2, reps=1, seed=2)</span>
<span class="sd">            observable = SparsePauliOp(&quot;ZZ&quot;)</span>
<span class="sd">            initial_point = np.random.random(ansatz.num_parameters)</span>
<span class="sd">            estimator = Estimator()</span>

<span class="sd">            def loss(x):</span>
<span class="sd">                job = estimator.run([ansatz], [observable], [x])</span>
<span class="sd">                return job.result().values[0]</span>

<span class="sd">            spsa = SPSA(maxiter=300)</span>
<span class="sd">            result = spsa.minimize(loss, x0=initial_point)</span>

<span class="sd">        To use the Hessian information, i.e. 2-SPSA, you can add ``second_order=True`` to the</span>
<span class="sd">        initializer of the ``SPSA`` class, the rest of the code remains the same.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            two_spsa = SPSA(maxiter=300, second_order=True)</span>
<span class="sd">            result = two_spsa.minimize(loss, x0=initial_point)</span>

<span class="sd">        The ``termination_checker`` can be used to implement a custom termination criterion.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            import numpy as np</span>
<span class="sd">            from qiskit_machine_learning.optimizers import SPSA</span>

<span class="sd">            def objective(x):</span>
<span class="sd">                return np.linalg.norm(x) + .04*np.random.rand(1)</span>

<span class="sd">            class TerminationChecker:</span>

<span class="sd">                def __init__(self, N : int):</span>
<span class="sd">                    self.N = N</span>
<span class="sd">                    self.values = []</span>

<span class="sd">                def __call__(self, nfev, parameters, value, stepsize, accepted) -&gt; bool:</span>
<span class="sd">                    self.values.append(value)</span>

<span class="sd">                    if len(self.values) &gt; self.N:</span>
<span class="sd">                        last_values = self.values[-self.N:]</span>
<span class="sd">                        pp = np.polyfit(range(self.N), last_values, 1)</span>
<span class="sd">                        slope = pp[0] / self.N</span>

<span class="sd">                        if slope &gt; 0:</span>
<span class="sd">                            return True</span>
<span class="sd">                    return False</span>

<span class="sd">            spsa = SPSA(maxiter=200, termination_checker=TerminationChecker(10))</span>
<span class="sd">            result = spsa.minimize(objective, x0=[0.5, 0.5])</span>
<span class="sd">            print(f&#39;SPSA completed after {result.nit} iterations&#39;)</span>

<span class="sd">    References:</span>

<span class="sd">        [1]: J. C. Spall (1998). An Overview of the Simultaneous Perturbation Method for Efficient</span>
<span class="sd">        Optimization, Johns Hopkins APL Technical Digest, 19(4), 482–492.</span>
<span class="sd">        `Online at jhuapl.edu. &lt;https://www.jhuapl.edu/SPSA/PDF-SPSA/Spall_An_Overview.PDF&gt;`_</span>

<span class="sd">        [2]: J. C. Spall (1997). Accelerated second-order stochastic optimization using only</span>
<span class="sd">        function measurements, Proceedings of the 36th IEEE Conference on Decision and Control,</span>
<span class="sd">        1417-1424 vol.2. `Online at IEEE.org. &lt;https://ieeexplore.ieee.org/document/657661&gt;`_</span>

<span class="sd">        [3]: A. Kandala et al. (2017). Hardware-efficient Variational Quantum Eigensolver for</span>
<span class="sd">        Small Molecules and Quantum Magnets. Nature 549, pages242–246(2017).</span>
<span class="sd">        `arXiv:1704.05018v2 &lt;https://arxiv.org/pdf/1704.05018v2.pdf#section*.11&gt;`_</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># pylint: disable=too-many-positional-arguments</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">maxiter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">blocking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">allowed_increase</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">trust_region</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Iterator</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">perturbation</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="n">Callable</span><span class="p">[[],</span> <span class="n">Iterator</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">last_avg</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">resamplings</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">perturbation_dims</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">second_order</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">regularization</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">hessian_delay</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">lse_solver</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">initial_hessian</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">callback</span><span class="p">:</span> <span class="n">CALLBACK</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">termination_checker</span><span class="p">:</span> <span class="n">TERMINATIONCHECKER</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            maxiter: The maximum number of iterations. Note that this is not the maximal number</span>
<span class="sd">                of function evaluations.</span>
<span class="sd">            blocking: If True, only accepts updates that improve the loss (up to some allowed</span>
<span class="sd">                increase, see next argument).</span>
<span class="sd">            allowed_increase: If ``blocking`` is ``True``, this argument determines by how much</span>
<span class="sd">                the loss can increase with the proposed parameters and still be accepted.</span>
<span class="sd">                If ``None``, the allowed increases is calibrated automatically to be twice the</span>
<span class="sd">                approximated standard deviation of the loss function.</span>
<span class="sd">            trust_region: If ``True``, restricts the norm of the update step to be :math:`\leq 1`.</span>
<span class="sd">            learning_rate: The update step is the learning rate is multiplied with the gradient.</span>
<span class="sd">                If the learning rate is a float, it remains constant over the course of the</span>
<span class="sd">                optimization. If a NumPy array, the :math:`i`-th element is the learning rate for</span>
<span class="sd">                the :math:`i`-th iteration. It can also be a callable returning an iterator which</span>
<span class="sd">                yields the learning rates for each optimization step.</span>
<span class="sd">                If ``learning_rate`` is set ``perturbation`` must also be provided.</span>
<span class="sd">            perturbation: Specifies the magnitude of the perturbation for the finite difference</span>
<span class="sd">                approximation of the gradients. See ``learning_rate`` for the supported types.</span>
<span class="sd">                If ``perturbation`` is set ``learning_rate`` must also be provided.</span>
<span class="sd">            last_avg: Return the average of the ``last_avg`` parameters instead of just the</span>
<span class="sd">                last parameter values.</span>
<span class="sd">            resamplings: The number of times the gradient (and Hessian) is sampled using a random</span>
<span class="sd">                direction to construct a gradient estimate. Per default the gradient is estimated</span>
<span class="sd">                using only one random direction. If an integer, all iterations use the same number</span>
<span class="sd">                of resamplings. If a dictionary, this is interpreted as</span>
<span class="sd">                ``{iteration: number of resamplings per iteration}``.</span>
<span class="sd">            perturbation_dims: The number of perturbed dimensions. Per default, all dimensions</span>
<span class="sd">                are perturbed, but a smaller, fixed number can be perturbed. If set, the perturbed</span>
<span class="sd">                dimensions are chosen uniformly at random.</span>
<span class="sd">            second_order: If True, use 2-SPSA instead of SPSA. In 2-SPSA, the Hessian is estimated</span>
<span class="sd">                additionally to the gradient, and the gradient is preconditioned with the inverse</span>
<span class="sd">                of the Hessian to improve convergence.</span>
<span class="sd">            regularization: To ensure the pre-conditioner is symmetric and positive definite, the</span>
<span class="sd">                identity times a small coefficient is added to it. This generator yields that</span>
<span class="sd">                coefficient.</span>
<span class="sd">            hessian_delay: Start multiplying the gradient with the inverse Hessian only after a</span>
<span class="sd">                certain number of iterations. The Hessian is still evaluated and therefore this</span>
<span class="sd">                argument can be useful to first get a stable average over the last iterations before</span>
<span class="sd">                using it as pre-conditioner.</span>
<span class="sd">            lse_solver: The method to solve for the inverse of the Hessian. Per default an</span>
<span class="sd">                exact LSE solver is used, but can e.g. be overwritten by a minimization routine.</span>
<span class="sd">            initial_hessian: The initial guess for the Hessian. By default, the identity matrix</span>
<span class="sd">                is used.</span>
<span class="sd">            callback: A callback function passed information in each iteration step. The</span>
<span class="sd">                information is, in this order: the number of function evaluations, the parameters,</span>
<span class="sd">                the function value, the step-size, whether the step was accepted.</span>
<span class="sd">            termination_checker: A callback function executed at the end of each iteration step. The</span>
<span class="sd">                arguments are, in this order: the parameters, the function value, the number</span>
<span class="sd">                of function evaluations, the step-size, whether the step was accepted. If the callback</span>
<span class="sd">                returns True, the optimization is terminated.</span>
<span class="sd">                To prevent additional evaluations of the objective method, if the objective has not yet</span>
<span class="sd">                been evaluated, the objective is estimated by taking the mean of the objective</span>
<span class="sd">                evaluations used in the estimate of the gradient.</span>


<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If ``learning_rate`` or ``perturbation`` is an array with fewer elements</span>
<span class="sd">                than the number of iterations.</span>


<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># general optimizer arguments</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span> <span class="o">=</span> <span class="n">maxiter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trust_region</span> <span class="o">=</span> <span class="n">trust_region</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="o">=</span> <span class="n">callback</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">termination_checker</span> <span class="o">=</span> <span class="n">termination_checker</span>

        <span class="c1"># if learning rate and perturbation are arrays, check they are sufficiently long</span>
        <span class="k">for</span> <span class="n">attr</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">perturbation</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="s2">&quot;perturbation&quot;</span><span class="p">]):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">maxiter</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Length of </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> is smaller than &#39;maxiter&#39; (</span><span class="si">{</span><span class="n">maxiter</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">perturbation</span> <span class="o">=</span> <span class="n">perturbation</span>

        <span class="c1"># SPSA specific arguments</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blocking</span> <span class="o">=</span> <span class="n">blocking</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">allowed_increase</span> <span class="o">=</span> <span class="n">allowed_increase</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_avg</span> <span class="o">=</span> <span class="n">last_avg</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resamplings</span> <span class="o">=</span> <span class="n">resamplings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">perturbation_dims</span> <span class="o">=</span> <span class="n">perturbation_dims</span>

        <span class="c1"># 2-SPSA specific arguments</span>
        <span class="k">if</span> <span class="n">regularization</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">regularization</span> <span class="o">=</span> <span class="mf">0.01</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">second_order</span> <span class="o">=</span> <span class="n">second_order</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hessian_delay</span> <span class="o">=</span> <span class="n">hessian_delay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lse_solver</span> <span class="o">=</span> <span class="n">lse_solver</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regularization</span> <span class="o">=</span> <span class="n">regularization</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_hessian</span> <span class="o">=</span> <span class="n">initial_hessian</span>

        <span class="c1"># runtime arguments</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_nfev</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># the number of function evaluations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_smoothed_hessian</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># smoothed average of the Hessians</span>

    <span class="c1"># pylint: disable=too-many-positional-arguments</span>
<div class="viewcode-block" id="SPSA.calibrate">
<a class="viewcode-back" href="../../../stubs/qiskit_machine_learning.optimizers.SPSA.html#qiskit_machine_learning.optimizers.SPSA.calibrate">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">calibrate</span><span class="p">(</span>
        <span class="n">loss</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="nb">float</span><span class="p">],</span>
        <span class="n">initial_point</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">c</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="n">stability_constant</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">target_magnitude</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># 2 pi / 10</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.602</span><span class="p">,</span>
        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.101</span><span class="p">,</span>
        <span class="n">modelspace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">max_evals_grouped</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Calibrate SPSA parameters with a power series as learning rate and perturbation coeffs.</span>

<span class="sd">        The power series are:</span>

<span class="sd">        .. math::</span>

<span class="sd">            a_k = \frac{a}{(A + k + 1)^\alpha}, c_k = \frac{c}{(k + 1)^\gamma}</span>

<span class="sd">        Args:</span>
<span class="sd">            loss: The loss function.</span>
<span class="sd">            initial_point: The initial guess of the iteration.</span>
<span class="sd">            c: The initial perturbation magnitude.</span>
<span class="sd">            stability_constant: The value of :math:`A`.</span>
<span class="sd">            target_magnitude: The target magnitude for the first update step, defaults to</span>
<span class="sd">                :math:`2\pi / 10`.</span>
<span class="sd">            alpha: The exponent of the learning rate power series.</span>
<span class="sd">            gamma: The exponent of the perturbation power series.</span>
<span class="sd">            modelspace: Whether the target magnitude is the difference of parameter values</span>
<span class="sd">                or function values (= model space).</span>
<span class="sd">            max_evals_grouped: The number of grouped evaluations supported by the loss function.</span>
<span class="sd">                Defaults to 1, i.e. no grouping.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple(generator, generator): A tuple of power series generators, the first one for the</span>
<span class="sd">                learning rate and the second one for the perturbation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;SPSA: Starting calibration of learning rate and perturbation.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">target_magnitude</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">target_magnitude</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">10</span>

        <span class="n">dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">initial_point</span><span class="p">)</span>

        <span class="c1"># compute the average magnitude of the first step</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="mi">25</span>
        <span class="n">points</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
            <span class="c1"># compute the random direction</span>
            <span class="n">pert</span> <span class="o">=</span> <span class="n">bernoulli_perturbation</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
            <span class="n">points</span> <span class="o">+=</span> <span class="p">[</span><span class="n">initial_point</span> <span class="o">+</span> <span class="n">c</span> <span class="o">*</span> <span class="n">pert</span><span class="p">,</span> <span class="n">initial_point</span> <span class="o">-</span> <span class="n">c</span> <span class="o">*</span> <span class="n">pert</span><span class="p">]</span>

        <span class="n">losses</span> <span class="o">=</span> <span class="n">_batch_evaluate</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">max_evals_grouped</span><span class="p">)</span>

        <span class="n">avg_magnitudes</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">losses</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">losses</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">avg_magnitudes</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">delta</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">c</span><span class="p">))</span>

        <span class="n">avg_magnitudes</span> <span class="o">/=</span> <span class="n">steps</span>

        <span class="k">if</span> <span class="n">modelspace</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">target_magnitude</span> <span class="o">/</span> <span class="p">(</span><span class="n">avg_magnitudes</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">target_magnitude</span> <span class="o">/</span> <span class="n">avg_magnitudes</span>

        <span class="c1"># compute the rescaling factor for correct first learning rate</span>
        <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;</span> <span class="mf">1e-10</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Calibration failed, using </span><span class="si">{</span><span class="n">target_magnitude</span><span class="si">}</span><span class="s2"> for `a`&quot;</span><span class="p">)</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">target_magnitude</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Finished calibration:&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot; -- Learning rate: a / ((A + n) ^ alpha) with a = </span><span class="si">%s</span><span class="s2">, A = </span><span class="si">%s</span><span class="s2">, alpha = </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">a</span><span class="p">,</span>
            <span class="n">stability_constant</span><span class="p">,</span>
            <span class="n">alpha</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot; -- Perturbation: c / (n ^ gamma) with c = </span><span class="si">%s</span><span class="s2">, gamma = </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">gamma</span><span class="p">)</span>

        <span class="c1"># set up the power series</span>
        <span class="k">def</span> <span class="nf">learning_rate</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">powerseries</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">stability_constant</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">perturbation</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">powerseries</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">gamma</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">perturbation</span></div>


<div class="viewcode-block" id="SPSA.estimate_stddev">
<a class="viewcode-back" href="../../../stubs/qiskit_machine_learning.optimizers.SPSA.html#qiskit_machine_learning.optimizers.SPSA.estimate_stddev">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">estimate_stddev</span><span class="p">(</span>
        <span class="n">loss</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="nb">float</span><span class="p">],</span>
        <span class="n">initial_point</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">avg</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span>
        <span class="n">max_evals_grouped</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Estimate the standard deviation of the loss function.&quot;&quot;&quot;</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">_batch_evaluate</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">avg</span> <span class="o">*</span> <span class="p">[</span><span class="n">initial_point</span><span class="p">],</span> <span class="n">max_evals_grouped</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">settings</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="c1"># if learning rate or perturbation are custom iterators expand them</span>
        <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">):</span>
            <span class="n">iterator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">()</span>
            <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span><span class="p">)])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>  <span class="c1"># type: ignore[assignment]</span>

        <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">perturbation</span><span class="p">):</span>
            <span class="n">iterator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">perturbation</span><span class="p">()</span>
            <span class="n">perturbation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span><span class="p">)])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">perturbation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">perturbation</span>  <span class="c1"># type: ignore[assignment]</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;maxiter&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span><span class="p">,</span>
            <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
            <span class="s2">&quot;perturbation&quot;</span><span class="p">:</span> <span class="n">perturbation</span><span class="p">,</span>
            <span class="s2">&quot;trust_region&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">trust_region</span><span class="p">,</span>
            <span class="s2">&quot;blocking&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocking</span><span class="p">,</span>
            <span class="s2">&quot;allowed_increase&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">allowed_increase</span><span class="p">,</span>
            <span class="s2">&quot;resamplings&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">resamplings</span><span class="p">,</span>
            <span class="s2">&quot;perturbation_dims&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">perturbation_dims</span><span class="p">,</span>
            <span class="s2">&quot;second_order&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">second_order</span><span class="p">,</span>
            <span class="s2">&quot;hessian_delay&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">hessian_delay</span><span class="p">,</span>
            <span class="s2">&quot;regularization&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularization</span><span class="p">,</span>
            <span class="s2">&quot;lse_solver&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">lse_solver</span><span class="p">,</span>
            <span class="s2">&quot;initial_hessian&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_hessian</span><span class="p">,</span>
            <span class="s2">&quot;callback&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">,</span>
            <span class="s2">&quot;termination_checker&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">termination_checker</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="c1"># pylint: disable=too-many-positional-arguments</span>
    <span class="k">def</span> <span class="nf">_point_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">delta1</span><span class="p">,</span> <span class="n">delta2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A single sample of the gradient at position ``x`` in direction ``delta``.&quot;&quot;&quot;</span>
        <span class="c1"># points to evaluate</span>
        <span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">delta1</span><span class="p">,</span> <span class="n">x</span> <span class="o">-</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">delta1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_nfev</span> <span class="o">+=</span> <span class="mi">2</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">second_order</span><span class="p">:</span>
            <span class="n">points</span> <span class="o">+=</span> <span class="p">[</span><span class="n">x</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="p">(</span><span class="n">delta1</span> <span class="o">+</span> <span class="n">delta2</span><span class="p">),</span> <span class="n">x</span> <span class="o">+</span> <span class="n">eps</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">delta1</span> <span class="o">+</span> <span class="n">delta2</span><span class="p">)]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_nfev</span> <span class="o">+=</span> <span class="mi">2</span>

        <span class="c1"># batch evaluate the points (if possible)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">_batch_evaluate</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_max_evals_grouped</span><span class="p">)</span>

        <span class="n">plus</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">minus</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">gradient_sample</span> <span class="o">=</span> <span class="p">(</span><span class="n">plus</span> <span class="o">-</span> <span class="n">minus</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">eps</span><span class="p">)</span> <span class="o">*</span> <span class="n">delta1</span>

        <span class="n">hessian_sample</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">second_order</span><span class="p">:</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">plus</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">-</span> <span class="n">minus</span><span class="p">)</span>
            <span class="n">diff</span> <span class="o">/=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">eps</span><span class="o">**</span><span class="mi">2</span>

            <span class="n">rank_one</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">delta1</span><span class="p">,</span> <span class="n">delta2</span><span class="p">)</span>
            <span class="n">hessian_sample</span> <span class="o">=</span> <span class="n">diff</span> <span class="o">*</span> <span class="p">(</span><span class="n">rank_one</span> <span class="o">+</span> <span class="n">rank_one</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">values</span><span class="p">),</span> <span class="n">gradient_sample</span><span class="p">,</span> <span class="n">hessian_sample</span>

    <span class="k">def</span> <span class="nf">_point_estimate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The gradient estimate at point x.&quot;&quot;&quot;</span>
        <span class="c1"># set up variables to store averages</span>
        <span class="n">value_estimate</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">gradient_estimate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
        <span class="n">hessian_estimate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>

        <span class="c1"># iterate over the directions</span>
        <span class="n">deltas1</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">bernoulli_perturbation</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">perturbation_dims</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">second_order</span><span class="p">:</span>
            <span class="n">deltas2</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">bernoulli_perturbation</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">perturbation_dims</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">deltas2</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
            <span class="n">delta1</span> <span class="o">=</span> <span class="n">deltas1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">delta2</span> <span class="o">=</span> <span class="n">deltas2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">second_order</span> <span class="k">else</span> <span class="kc">None</span>

            <span class="n">value_sample</span><span class="p">,</span> <span class="n">gradient_sample</span><span class="p">,</span> <span class="n">hessian_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_point_sample</span><span class="p">(</span>
                <span class="n">loss</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">delta1</span><span class="p">,</span> <span class="n">delta2</span>
            <span class="p">)</span>
            <span class="n">value_estimate</span> <span class="o">+=</span> <span class="n">value_sample</span>
            <span class="n">gradient_estimate</span> <span class="o">+=</span> <span class="n">gradient_sample</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">second_order</span><span class="p">:</span>
                <span class="n">hessian_estimate</span> <span class="o">+=</span> <span class="n">hessian_sample</span>

        <span class="k">return</span> <span class="p">(</span>
            <span class="n">value_estimate</span> <span class="o">/</span> <span class="n">num_samples</span><span class="p">,</span>
            <span class="n">gradient_estimate</span> <span class="o">/</span> <span class="n">num_samples</span><span class="p">,</span>
            <span class="n">hessian_estimate</span> <span class="o">/</span> <span class="n">num_samples</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># pylint: disable=too-many-positional-arguments</span>
    <span class="k">def</span> <span class="nf">_compute_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">lse_solver</span><span class="p">):</span>
        <span class="c1"># compute the perturbations</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">resamplings</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">num_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resamplings</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">num_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resamplings</span>

        <span class="c1"># accumulate the number of samples</span>
        <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span><span class="p">,</span> <span class="n">hessian</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_point_estimate</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>

        <span class="c1"># precondition gradient with inverse Hessian, if specified</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">second_order</span><span class="p">:</span>
            <span class="n">smoothed</span> <span class="o">=</span> <span class="n">k</span> <span class="o">/</span> <span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_smoothed_hessian</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">hessian</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_smoothed_hessian</span> <span class="o">=</span> <span class="n">smoothed</span>

            <span class="k">if</span> <span class="n">k</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">hessian_delay</span><span class="p">:</span>
                <span class="n">spd_hessian</span> <span class="o">=</span> <span class="n">_make_spd</span><span class="p">(</span><span class="n">smoothed</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">regularization</span><span class="p">)</span>

                <span class="c1"># solve for the gradient update</span>
                <span class="n">gradient</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">lse_solver</span><span class="p">(</span><span class="n">spd_hessian</span><span class="p">,</span> <span class="n">gradient</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">value</span><span class="p">,</span> <span class="n">gradient</span>

<div class="viewcode-block" id="SPSA.minimize">
<a class="viewcode-back" href="../../../stubs/qiskit_machine_learning.optimizers.SPSA.html#qiskit_machine_learning.optimizers.SPSA.minimize">[docs]</a>
    <span class="k">def</span> <span class="nf">minimize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fun</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">POINT</span><span class="p">],</span> <span class="nb">float</span><span class="p">],</span>
        <span class="n">x0</span><span class="p">:</span> <span class="n">POINT</span><span class="p">,</span>
        <span class="n">jac</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">POINT</span><span class="p">],</span> <span class="n">POINT</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">bounds</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OptimizerResult</span><span class="p">:</span>
        <span class="c1"># ensure learning rate and perturbation are correctly set: either none or both</span>
        <span class="c1"># this happens only here because for the calibration the loss function is required</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">perturbation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">get_eta</span><span class="p">,</span> <span class="n">get_eps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">calibrate</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">max_evals_grouped</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_evals_grouped</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">get_eta</span><span class="p">,</span> <span class="n">get_eps</span> <span class="o">=</span> <span class="n">_validate_pert_and_learningrate</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">perturbation</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span>
            <span class="p">)</span>
        <span class="n">eta</span><span class="p">,</span> <span class="n">eps</span> <span class="o">=</span> <span class="n">get_eta</span><span class="p">(),</span> <span class="n">get_eps</span><span class="p">()</span>

        <span class="n">lse_solver</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lse_solver</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lse_solver</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lse_solver</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span>

        <span class="c1"># prepare some initials</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_hessian</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_smoothed_hessian</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_smoothed_hessian</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_hessian</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_nfev</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># if blocking is enabled we need to keep track of the function values</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocking</span><span class="p">:</span>
            <span class="n">fx</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># pylint: disable=invalid-name</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_nfev</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">allowed_increase</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">allowed_increase</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimate_stddev</span><span class="p">(</span>
                    <span class="n">fun</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">max_evals_grouped</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_max_evals_grouped</span>
                <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;SPSA: Starting optimization.&quot;</span><span class="p">)</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

        <span class="c1"># keep track of the last few steps to return their average</span>
        <span class="n">last_steps</span> <span class="o">=</span> <span class="n">deque</span><span class="p">([</span><span class="n">x</span><span class="p">])</span>

        <span class="c1"># use a local variable and while loop to keep track of the number of iterations</span>
        <span class="c1"># if the termination checker terminates early</span>
        <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span><span class="p">:</span>
            <span class="n">k</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">iteration_start</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
            <span class="c1"># compute update</span>
            <span class="n">fx_estimate</span><span class="p">,</span> <span class="n">update</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_update</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="nb">next</span><span class="p">(</span><span class="n">eps</span><span class="p">),</span> <span class="n">lse_solver</span><span class="p">)</span>

            <span class="c1"># trust region</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trust_region</span><span class="p">:</span>
                <span class="n">norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">update</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">norm</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># stop from dividing by 0</span>
                    <span class="n">update</span> <span class="o">=</span> <span class="n">update</span> <span class="o">/</span> <span class="n">norm</span>

            <span class="c1"># compute next parameter value</span>
            <span class="n">update</span> <span class="o">=</span> <span class="n">update</span> <span class="o">*</span> <span class="nb">next</span><span class="p">(</span><span class="n">eta</span><span class="p">)</span>
            <span class="n">x_next</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">update</span>
            <span class="n">fx_next</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># blocking</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocking</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_nfev</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">fx_next</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">x_next</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">fx</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">allowed_increase</span> <span class="o">&lt;=</span> <span class="n">fx_next</span><span class="p">:</span>  <span class="c1"># accept only if loss improved</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">(</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_nfev</span><span class="p">,</span>  <span class="c1"># number of function evals</span>
                            <span class="n">x_next</span><span class="p">,</span>  <span class="c1"># next parameters</span>
                            <span class="n">fx_next</span><span class="p">,</span>  <span class="c1"># loss at next parameters</span>
                            <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">update</span><span class="p">),</span>  <span class="c1"># size of the update step</span>
                            <span class="kc">False</span><span class="p">,</span>
                        <span class="p">)</span>  <span class="c1"># not accepted</span>

                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                        <span class="s2">&quot;Iteration </span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2"> rejected in </span><span class="si">%s</span><span class="s2">.&quot;</span><span class="p">,</span>
                        <span class="n">k</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                        <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">iteration_start</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="k">continue</span>
                <span class="n">fx</span> <span class="o">=</span> <span class="n">fx_next</span>  <span class="c1"># pylint: disable=invalid-name</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s2">&quot;Iteration </span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2"> done in </span><span class="si">%s</span><span class="s2">.&quot;</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">iteration_start</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># if we didn&#39;t evaluate the function yet, do it now</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">blocking</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_nfev</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">fx_next</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">x_next</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">callback</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_nfev</span><span class="p">,</span>  <span class="c1"># number of function evals</span>
                    <span class="n">x_next</span><span class="p">,</span>  <span class="c1"># next parameters</span>
                    <span class="n">fx_next</span><span class="p">,</span>  <span class="c1"># loss at next parameters</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">update</span><span class="p">),</span>  <span class="c1"># size of the update step</span>
                    <span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>  <span class="c1"># accepted</span>

            <span class="c1"># update parameters</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x_next</span>

            <span class="c1"># update the list of the last ``last_avg`` parameters</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_avg</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">last_steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_next</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">last_steps</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_avg</span><span class="p">:</span>
                    <span class="n">last_steps</span><span class="o">.</span><span class="n">popleft</span><span class="p">()</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">termination_checker</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">fx_check</span> <span class="o">=</span> <span class="n">fx_estimate</span> <span class="k">if</span> <span class="n">fx_next</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">fx_next</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">termination_checker</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_nfev</span><span class="p">,</span> <span class="n">x_next</span><span class="p">,</span> <span class="n">fx_check</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">update</span><span class="p">),</span> <span class="kc">True</span>
                <span class="p">):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Terminated optimization at </span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2"> iterations.&quot;</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">maxiter</span><span class="p">)</span>
                    <span class="k">break</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;SPSA: Finished in </span><span class="si">%s</span><span class="s2">.&quot;</span><span class="p">,</span> <span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_avg</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">last_steps</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">OptimizerResult</span><span class="p">()</span>
        <span class="n">result</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">result</span><span class="o">.</span><span class="n">fun</span> <span class="o">=</span> <span class="n">fun</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">result</span><span class="o">.</span><span class="n">nfev</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nfev</span>
        <span class="n">result</span><span class="o">.</span><span class="n">nit</span> <span class="o">=</span> <span class="n">k</span>

        <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="SPSA.get_support_level">
<a class="viewcode-back" href="../../../stubs/qiskit_machine_learning.optimizers.SPSA.html#qiskit_machine_learning.optimizers.SPSA.get_support_level">[docs]</a>
    <span class="k">def</span> <span class="nf">get_support_level</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the support level dictionary.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;gradient&quot;</span><span class="p">:</span> <span class="n">OptimizerSupportLevel</span><span class="o">.</span><span class="n">ignored</span><span class="p">,</span>
            <span class="s2">&quot;bounds&quot;</span><span class="p">:</span> <span class="n">OptimizerSupportLevel</span><span class="o">.</span><span class="n">ignored</span><span class="p">,</span>
            <span class="s2">&quot;initial_point&quot;</span><span class="p">:</span> <span class="n">OptimizerSupportLevel</span><span class="o">.</span><span class="n">required</span><span class="p">,</span>
        <span class="p">}</span></div>
</div>



<span class="k">def</span> <span class="nf">bernoulli_perturbation</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">perturbation_dims</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get a Bernoulli random perturbation.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">perturbation_dims</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">algorithm_globals</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>

    <span class="n">pert</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">algorithm_globals</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">perturbation_dims</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">algorithm_globals</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
        <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">dim</span><span class="p">)),</span> <span class="n">size</span><span class="o">=</span><span class="n">perturbation_dims</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
    <span class="n">result</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">pert</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">powerseries</span><span class="p">(</span><span class="n">eta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Yield a series decreasing by a power law.&quot;&quot;&quot;</span>

    <span class="n">n</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">eta</span> <span class="o">/</span> <span class="p">((</span><span class="n">n</span> <span class="o">+</span> <span class="n">offset</span><span class="p">)</span> <span class="o">**</span> <span class="n">power</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>


<span class="k">def</span> <span class="nf">constant</span><span class="p">(</span><span class="n">eta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Yield a constant series.&quot;&quot;&quot;</span>

    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">eta</span>


<span class="k">def</span> <span class="nf">_batch_evaluate</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">max_evals_grouped</span><span class="p">,</span> <span class="n">unpack_points</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate a function on all points with batches of max_evals_grouped.</span>

<span class="sd">    The points are a list of inputs, as ``[in1, in2, in3, ...]``. If the individual</span>
<span class="sd">    inputs are tuples (because the function takes multiple inputs), set ``unpack_points`` to ``True``.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># if the function cannot handle lists of points as input, cover this case immediately</span>
    <span class="k">if</span> <span class="n">max_evals_grouped</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">max_evals_grouped</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># support functions with multiple arguments where the points are given in a tuple</span>
        <span class="k">return</span> <span class="p">[</span>
            <span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="n">point</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">point</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="n">function</span><span class="p">(</span><span class="n">point</span><span class="p">)</span> <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">points</span>
        <span class="p">]</span>

    <span class="n">num_points</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>

    <span class="c1"># get the number of batches</span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="n">num_points</span> <span class="o">//</span> <span class="n">max_evals_grouped</span>
    <span class="k">if</span> <span class="n">num_points</span> <span class="o">%</span> <span class="n">max_evals_grouped</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">num_batches</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="c1"># split the points</span>
    <span class="n">batched_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">points</span><span class="p">),</span> <span class="n">num_batches</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">batched_points</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">unpack_points</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">_repack_points</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
            <span class="n">results</span> <span class="o">+=</span> <span class="n">_as_list</span><span class="p">(</span><span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">results</span> <span class="o">+=</span> <span class="n">_as_list</span><span class="p">(</span><span class="n">function</span><span class="p">(</span><span class="n">batch</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">results</span>


<span class="k">def</span> <span class="nf">_as_list</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Convert a list or numpy array into a list.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">obj</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">else</span> <span class="n">obj</span>


<span class="k">def</span> <span class="nf">_repack_points</span><span class="p">(</span><span class="n">points</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Turn a list of tuples of points into a tuple of lists of points.</span>
<span class="sd">    E.g. turns</span>
<span class="sd">        [(a1, a2, a3), (b1, b2, b3)]</span>
<span class="sd">    into</span>
<span class="sd">        ([a1, b1], [a2, b2], [a3, b3])</span>
<span class="sd">    where all elements are np.ndarray.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_sets</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># length of (a1, a2, a3)</span>
    <span class="k">return</span> <span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">points</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_sets</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_make_spd</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="n">identity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">psd</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">sqrtm</span><span class="p">(</span><span class="n">matrix</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">matrix</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">psd</span> <span class="o">+</span> <span class="n">bias</span> <span class="o">*</span> <span class="n">identity</span>


<span class="k">def</span> <span class="nf">_validate_pert_and_learningrate</span><span class="p">(</span><span class="n">perturbation</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">learning_rate</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">perturbation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;If one of learning rate or perturbation is set, both must be set.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">perturbation</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>

        <span class="k">def</span> <span class="nf">get_eps</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">constant</span><span class="p">(</span><span class="n">perturbation</span><span class="p">)</span>

    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">perturbation</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>

        <span class="k">def</span> <span class="nf">get_eps</span><span class="p">():</span>
            <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="n">perturbation</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">get_eps</span> <span class="o">=</span> <span class="n">perturbation</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>

        <span class="k">def</span> <span class="nf">get_eta</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">constant</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)):</span>

        <span class="k">def</span> <span class="nf">get_eta</span><span class="p">():</span>
            <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">get_eta</span> <span class="o">=</span> <span class="n">learning_rate</span>

    <span class="k">return</span> <span class="n">get_eta</span><span class="p">,</span> <span class="n">get_eps</span>
</pre></div>
        </article>
      </div>
      <footer>
        
  <script>
    function userFeedbackClicked(ctaType) {
      document.getElementById('qiskit-analytics-thank-you').style.visibility = 'visible';
      window.trackCta(`Helpful - ${ctaType}`);
    }
  </script>
    <div class="qiskit-analytics-container">
      <div>Was this page helpful?</div>
      <a onclick="userFeedbackClicked('yes')">Yes</a>
      <a onclick="userFeedbackClicked('no')">No</a>
      <div id="qiskit-analytics-thank-you">Thank you!</div>
    </div>
<div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2018, 2024, Qiskit Machine Learning Development Team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script src="../../../_static/jquery.js?v=5d32c60e"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../../../_static/documentation_options.js?v=dbee5847"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/thebelab-helper.js"></script>
    <script src="../../../_static/scripts/qiskit-sphinx-theme.js?v=4d77b8ca"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>